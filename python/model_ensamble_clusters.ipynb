{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# --- RANDOM FORREST BIN - 100 ----\n",
    "# --- RANDOM FORREST PRED - 150 ---\n",
    "# ---------------------------------\n",
    "# -------- theta_vals = 10 --------\n",
    "# -- clusters [count x av_theta] --\t| 2\t\t\t\t\t\t| 5\t\t\t\t\t\t| 10\t\t\t\t\t| 40\n",
    "# ------ 0.2 < z axis < 0.2 -------\n",
    "# ----- fill 0 if count < 10 ------\n",
    "# ------------ count in -----------\n",
    "# ------------- neigh -------------\n",
    "# Accuracy bin:\t\t\t\t\t\t| 0.966592875\t\t\t| 0.96903975\t\t\t| 0.96955025\t\t\t| 0.969550625\n",
    "# Accuracy pred:\t\t\t\t\t| 0.892982375\t\t\t| 0.89498375\t\t\t| 0.895364875\t\t\t| 0.89544375\n",
    "# score:\n",
    "# (offset)\t14:\t\t\t\t\t\t| 0.04200295091397502\t| 0.04195688082531596\t| 0.041679132835804274\t| 0.041280252179147166\n",
    "#\n",
    "# input:\toutput_theta_vals7\t\t| \n",
    "# output:\t\t\t\t\t\t\t| pred_ensamble_bin11\t| pred_ensamble_bin12\t| pred_ensamble_bin13\t| pred_ensamble_bin14\n",
    "#\t\t\t\t\t\t\t\t\t| pred_ensamble13\t\t| pred_ensamble14\t\t| pred_ensamble15\t\t| pred_ensamble16\n",
    "#\n",
    "# scores:\t\t\t\t\t\t\t| 14_neigh.csv\t\t\t| 14_1_neigh.csv\t\t| 14_2_neigh.csv\t\t| 14_3_neigh.csv\n",
    "# ---------------------------------\n",
    "# ---------------------------------\n",
    "# --- RANDOM FORREST BIN - 100 ----\n",
    "# --- RANDOM FORREST PRED - 150 ---\n",
    "# ---------------------------------\n",
    "# -------- theta_vals = 10 --------\n",
    "# -- clusters [count x av_theta] --\t| 10\t\t\t\t\t| 2\n",
    "# ------ 0.2 < z axis < 0.2 -------\n",
    "# ----- fill 0 if count < 10 ------\n",
    "# ------------ count in -----------\n",
    "# ----------- neigh full ----------\n",
    "# Accuracy bin:\t\t\t\t\t\t| 0.969025875\t\t\t| \n",
    "# Accuracy pred:\t\t\t\t\t| 0.8960345\t\t\t\t| \n",
    "# score:\n",
    "# (offset)\t15:\t\t\t\t\t\t| 0.041436279971244445\t| \n",
    "#\n",
    "# input:\toutput_theta_vals7\t\t| \n",
    "# output:\t\t\t\t\t\t\t| pred_ensamble_bin15\t| pred_ensamble_bin16\n",
    "#\t\t\t\t\t\t\t\t\t| pred_ensamble17\t\t| pred_ensamble18\n",
    "#\n",
    "# scores:\t\t\t\t\t\t\t| 15_neigh.csv\t\t\t| 15_1_neigh.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_data = glob.glob(os.path.join(\"../data/output/\", \"*.csv\"))\n",
    "all_files_data.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "train_data = pd.concat((pd.read_csv(f, header=None) for f in all_files_data[:15000]), ignore_index=True)\n",
    "test_data = pd.concat((pd.read_csv(f, header=None) for f in all_files_data[15000:]), ignore_index=True)\n",
    "\n",
    "all_files_target = glob.glob(os.path.join(\"../data/training_ground_truth_files\", \"*_ground\"))\n",
    "all_files_target.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "target_train = pd.concat((pd.read_csv(f, header=None, sep=' ', dtype=\"int8\").stack() for f in all_files_target[:15000]), ignore_index=True)\n",
    "target_test = pd.concat((pd.read_csv(f, header=None, sep=' ', dtype=\"int8\").stack() for f in all_files_target[15000:]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jan/Documents/Magisterka/c_test/model_ensamble_clusters.ipynb Cell 4\u001b[0m in \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jan/Documents/Magisterka/c_test/model_ensamble_clusters.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_count \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(train_data[train_data\u001b[39m.\u001b[39mcolumns[\u001b[39m0\u001b[39m]])\u001b[39m.\u001b[39mflatten()\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jan/Documents/Magisterka/c_test/model_ensamble_clusters.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_count \u001b[39m=\u001b[39m train_count\u001b[39m.\u001b[39mreshape(\u001b[39m15000\u001b[39m,\u001b[39m1600\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jan/Documents/Magisterka/c_test/model_ensamble_clusters.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m test_d \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(test_data[test_data\u001b[39m.\u001b[39mcolumns[\u001b[39m1\u001b[39m:\u001b[39m10\u001b[39m]])\u001b[39m.\u001b[39mflatten()\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jan/Documents/Magisterka/c_test/model_ensamble_clusters.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m test_d \u001b[39m=\u001b[39m test_d\u001b[39m.\u001b[39mreshape(\u001b[39m5000\u001b[39m,\u001b[39m14400\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jan/Documents/Magisterka/c_test/model_ensamble_clusters.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m test_count \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(test_data[test_data\u001b[39m.\u001b[39mcolumns[\u001b[39m0\u001b[39m]])\u001b[39m.\u001b[39mflatten()\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "train_d = np.array(train_data[train_data.columns[1:10]]).flatten().reshape(-1) # should be 11?\n",
    "train_d = train_d.reshape(15000,14400)\n",
    "train_count = np.array(train_data[train_data.columns[0]]).flatten().reshape(-1)\n",
    "train_count = train_count.reshape(15000,1600)\n",
    "\n",
    "test_d = np.array(test_data[test_data.columns[1:10]]).flatten().reshape(-1)\n",
    "test_d = test_d.reshape(5000,14400)\n",
    "test_count = np.array(test_data[test_data.columns[0]]).flatten().reshape(-1)\n",
    "test_count = test_count.reshape(5000,1600)\n",
    "\n",
    "data = np.concatenate([train_d,test_d])\n",
    "data = data.reshape(20000,14400)\n",
    "data_c = np.concatenate([train_count,test_count])\n",
    "data_c = data_c.reshape(20000,1600)\n",
    "\n",
    "means = np.array([[np.mean(ar_c),np.mean(ar_d)] for ar_c,ar_d in zip(data_c,data)]) # mean of rows (count, theta), row size = 1600\n",
    "\n",
    "del all_files_data, all_files_target, train_d, test_d, data, data_c, train_count, test_count\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to separate only air samples from other samples\n",
    "\n",
    "# Cluster means\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_of_clusters = 2\n",
    "kmeans = KMeans(n_of_clusters)\n",
    "kmeans.fit(means)\n",
    "clusters = kmeans.fit_predict(means)\n",
    "\n",
    "cluster_train = np.repeat(clusters[:15000], 1600)\n",
    "cluster_test = np.repeat(clusters[15000:], 1600)\n",
    "\n",
    "train_data_clusters = [train_data[cluster_train==i] for i in range(n_of_clusters)]\n",
    "train_target_clusters = [target_train[cluster_train==i] for i in range(n_of_clusters)]\n",
    "test_data_clusters = [test_data[cluster_test==i] for i in range(n_of_clusters)]\n",
    "\n",
    "del kmeans, cluster_train, clusters\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forrest - binary class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dec_tree_bin_cluster_preds = []\n",
    "for c in range(n_of_clusters):\n",
    "\tbin_target_train = np.where(train_target_clusters[c] == 0, False, True)\n",
    "\tcrf = RandomForestClassifier(n_estimators=100, n_jobs=20)\n",
    "\tcrf.fit(train_data_clusters[c], bin_target_train)\n",
    "\tdec_tree_bin_cluster_preds += [crf.predict(test_data_clusters[c])]\n",
    "\n",
    "\tprint(c)\n",
    "\n",
    "\tdel crf, bin_target_train\n",
    "\tgc.collect()\n",
    "\n",
    "\n",
    "dec_tree_bin_preds = []\n",
    "idxs = [0 for i in range(n_of_clusters)]\n",
    "for c in cluster_test:\n",
    "\tdec_tree_bin_preds += [dec_tree_bin_cluster_preds[c][idxs[c]]]\n",
    "\tidxs[c] += 1\n",
    "\n",
    "\n",
    "off = np.zeros((40,40), dtype='bool')\n",
    "off[5:35,5:35] = 1\n",
    "off_test = np.concatenate([off for i in range(5000)], axis=None)\n",
    "\n",
    "dec_tree_bin_preds = np.array(dec_tree_bin_preds)\n",
    "dec_tree_bin_preds *= off_test\n",
    "\n",
    "dec_bin_preds = dec_tree_bin_preds.reshape((5000,40,40)).astype(bool)\n",
    "# target_pred_neigh = np.zeros((5000,40,40))\n",
    "\n",
    "neigh_idx = 0\n",
    "flag = True\n",
    "while flag:\n",
    "\tprint(neigh_idx)\n",
    "\n",
    "\tflag = False\n",
    "\ttarget_pred_neigh = np.zeros((5000,40,40))\n",
    "\tfor idx,grid in enumerate(dec_bin_preds):\n",
    "\t\tfor x in range(6,35):\n",
    "\t\t\tfor y in range(6,35):\n",
    "\t\t\t\tneigh = np.sum([grid[x-1,y-1], grid[x,y-1], grid[x+1,y-1], grid[x-1,y], grid[x+1,y], grid[x-1,y+1], grid[x,y+1], grid[x+1,y+1]])\n",
    "\n",
    "\t\t\t\tif grid[x,y] == 0:\n",
    "\t\t\t\t\tif neigh > 5:\n",
    "\t\t\t\t\t\ttarget_pred_neigh[idx][x,y] = 1\n",
    "\t\t\t\t\t\tflag = True\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\ttarget_pred_neigh[idx][x,y] = 1\n",
    "\n",
    "\tdec_bin_preds = target_pred_neigh\n",
    "\tneigh_idx += 1\n",
    "\n",
    "for idx,grid in enumerate(dec_bin_preds):\n",
    "\tfor x in range(6,35):\n",
    "\t\tfor y in range(6,35):\n",
    "\t\t\tneigh = np.sum([grid[x-1,y-1], grid[x,y-1], grid[x+1,y-1], grid[x-1,y], grid[x+1,y], grid[x-1,y+1], grid[x,y+1], grid[x+1,y+1]])\n",
    "\n",
    "\t\t\tif grid[x,y] == 1 and neigh < 3:\n",
    "\t\t\t\ttarget_pred_neigh[idx][x,y] = 0\n",
    "\n",
    "\n",
    "target_pred_neigh = target_pred_neigh.flatten().astype(bool)\n",
    "dec_tree_bin_cluster_preds_neigh = []\n",
    "for c in range(n_of_clusters):\n",
    "\tdec_tree_bin_cluster_preds_neigh += [target_pred_neigh[cluster_test==c].astype(bool)]\n",
    "\n",
    "\n",
    "bin_test_target = np.where(target_test == 0, False, True)\n",
    "print(\"Accuracy:\", accuracy_score(bin_test_target, dec_tree_bin_preds))\n",
    "print(\"Accuracy:\", accuracy_score(bin_test_target, target_pred_neigh))\n",
    "\n",
    "idx = 15000\n",
    "for grid in target_pred_neigh.reshape(5000,40,40):\n",
    "\tgr_name = \"pred/pred_ensamble_bin16/\" + str(idx) + \"_pred\"\n",
    "\tnp.savetxt(gr_name, grid, fmt='%i')\n",
    "\tidx += 1\n",
    "\n",
    "del target_pred_neigh, dec_tree_bin_preds, bin_test_target, dec_bin_preds, dec_tree_bin_cluster_preds, off\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forrest - multiclass\n",
    "dec_tree_class_cluster_preds = []\n",
    "for c in range(n_of_clusters):\n",
    "\tcrf = RandomForestClassifier(n_estimators=150, n_jobs=20)\n",
    "\tcrf.fit(train_data_clusters[c][train_target_clusters[c]!=0], train_target_clusters[c][train_target_clusters[c]!=0])\n",
    "\tdec_tree_class_cluster_preds += [crf.predict(test_data_clusters[c][dec_tree_bin_cluster_preds_neigh[c]])]\n",
    "\n",
    "\tprint(c)\n",
    "\n",
    "\tdel crf\n",
    "\tgc.collect()\n",
    "\n",
    "\n",
    "idxs_bin = [0 for i in range(n_of_clusters)]\n",
    "idxs_class = [0 for i in range(n_of_clusters)]\n",
    "dec_tree_preds = []\n",
    "for c in cluster_test:\n",
    "\tif dec_tree_bin_cluster_preds_neigh[c][idxs_bin[c]]:\n",
    "\t\tdec_tree_preds += [dec_tree_class_cluster_preds[c][idxs_class[c]]]\n",
    "\t\tidxs_class[c] += 1\n",
    "\telse:\n",
    "\t\tdec_tree_preds += [0]\n",
    "\tidxs_bin[c] += 1\n",
    "\n",
    "\n",
    "dec_tree_preds = np.array(dec_tree_preds)\n",
    "dec_tree_preds *= off_test\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(target_test, dec_tree_preds))\n",
    "\n",
    "\n",
    "idx = 15000\n",
    "for grid in dec_tree_preds.reshape(5000,40,40):\n",
    "\tgr_name = \"pred/pred_ensamble18/\" + str(idx) + \"_pred\"\n",
    "\tnp.savetxt(gr_name, grid, fmt='%i')\n",
    "\tidx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def aIOU(predictions, gt):\n",
    "    classes = np.unique(np.concatenate((np.unique(predictions), np.unique(gt))))\n",
    "    IoUs = np.zeros(len(classes) - 1)\n",
    "    i = 0\n",
    "    for cls in classes:\n",
    "        if cls != 0:\n",
    "            preds_tmp = predictions == cls\n",
    "            gt_tmp = gt == cls\n",
    "            IoUs[i] = np.sum(np.logical_and(preds_tmp, gt_tmp)) / np.sum(np.logical_or(preds_tmp, gt_tmp))\n",
    "            i += 1\n",
    "    return np.mean(IoUs)\n",
    "\n",
    "dec_tree_eval = dec_tree_preds.reshape((5000,1600))\n",
    "target_eval = np.array(target_test).reshape((5000,1600))\n",
    "\n",
    "score = np.mean([aIOU(dec_tree_eval[i], target_eval[i]) for i in range(len(dec_tree_eval))])\n",
    "print(score)\n",
    "\n",
    "# Output scores\n",
    "output = np.array([dec_tree_preds.reshape(5000,40,40)[i].T.reshape(1600) for i in range(5000)])\n",
    "np.savetxt(\"scores/15_1_neigh.csv\", output, fmt='%i', delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
